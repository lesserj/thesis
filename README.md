# Thesis

This is the code used to generate the data for my thesis "Detecting Fires: A Nationally Consistent, Rule Based Approach."

## About the code

The majority of this code is written as Python scripts designed to be run sequentially. The machine learning algorithm is Cubist, written by Ross Quinlan at RuleQuest and can be found at https://www.rulequest.com.  The version of Cubist used is a modified version of the Cubist-R project and matches up most closely with version 2.07 of Cubist.  The Cubist_Interpreter, if memory serves correctly, is a re-compiled version of CubistSam.exe, which is available as part of the Cubist GPL Download on the Rulequest.com website.  You cannot mismatch versions of Cubist and the Cubist_Interpreter.

The code should work on either the 2.7.x or 3.x versions of Python, however, it is most tested on the 2.7.x branch.  These scripts can be memory intensive.  If you are running this code on large rasters, use the 64 bit version of Python, otherwise you may run into memory errors.

## How to run

These scripts are meant to be run consequetively.  They are highly designed around my data and environment and will need to be modified heavily for use in other applications.

**01_prepBaer.py**: This file iterates through all the Burned Area Emergency Response rasters (https://fsapps.nwcg.gov/afm/baer/download.php) and calculates the bounding box of the rasters in Albers projection.  These bounding boxes are stored in a perimeter.txt file.

**02_extract.py**: This file extracts all the pixel data from a series of 6 Landsat scenes over a 3 year period that intersect with our BAER data.  The Landsat data is preprocessed to have identical extents and data masks.  It uses the perimeter.txt file generated by 01_prepBaer.py to determine areas that need extracting.  Extracted pixel values are stored in text files used to train our cubist model.

**03_prepTestData.py**: This file combines training data from neighboring scenes and builds a rule model using Cubist.

**04_applyTree.py**: This file takes the Cubist generated model and applies it to a new series of Landsat scenes.  This builds a new raster that classifies points on a likely not burned to burned scale.  The extracted pixel data is sent to an intermediate text file in chunks and read in by the cubist interpreter.  The results are output to a text file and read back in and converted to a raster.  This is slow and un-elegant, but it gets the job done.

**05_prepAnalysis.py**: This file converts the output raster as a binary raster using a threshold value to determine whether a pixel is considered burned/unburned.  The detection threshold for my thesis is 90, but can be adjusted by changing the DETECTION_THRESHOLD variable.  This file also builds masks of BAER data where we know changed occured, for later manual analysis of results.

**config.py**: A small helper file for loading the settings.ini file.

**settings.ini**: This file sets the paths for all the data and executables in the project.  It will need to be modified to match your development setup.